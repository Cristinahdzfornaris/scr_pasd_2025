# docker-compose.yml (VERSIÓN FINAL - RESILIENTE)

services:
  # Los servicios de Ray no cambian. ray-head sigue siendo el SPOF principal por diseño.
  ray-head:
    build: .
    # Ya no usamos container_name para facilitar el escalado, aunque en head no es estrictamente necesario.
    ports:
      - "8265:8265"
      - "10001:10001"
    command: |
      bash -c "
        ray start --head --num-cpus=1 --port=6379 --dashboard-host=0.0.0.0 --include-dashboard=true --ray-client-server-port=10001 --resources='{\"is_head_node\": 1}' && \
        echo 'Nodo HEAD en marcha...' && \
        tail -f /dev/null
      "
    shm_size: 2.5gb

  ray-worker: # Unificamos los workers para facilitar el escalado
    build: .
    depends_on:
      - ray-head
    deploy:
      replicas: 2 # Podemos escalar los workers de Ray fácilmente
    command: |
      bash -c "
        ray start --address=ray-head:6379 --num-cpus=2 && \
        echo 'Worker conectado al HEAD' && \
        tail -f /dev/null
      "
    shm_size: 2.5gb
  
  # SOLUCIÓN #1: Replicación del servicio crítico
  management-api:
    build: .
    # Ya no se usa container_name para permitir la replicación.
    # Ya no se exponen puertos, la comunicación es interna a través de la GUI.
    deploy:
      replicas: 3 # Creamos un grupo de 3 réplicas para alta disponibilidad.
    environment:
      - RAY_ADDRESS=ray://ray-head:10001
      - SERVICE_NAME=management-api # Para que el cliente resiliente sepa a quién buscar
    command: uvicorn management_api:app --host 0.0.0.0 --port 9000
    # Quitamos el healthcheck porque la GUI ahora es responsable de manejar los fallos.
  
  # Hacemos lo mismo para el servicio de inferencia para consistencia
  api-service:
    build: .
    deploy:
      replicas: 3 # También replicamos el servicio de inferencia.
    # ports:
      # Exponemos este puerto para que sea más fácil de probar externamente (ej. con curl)
      # Pero idealmente, la GUI también usaría un cliente resiliente para este.
      # - "8000:8000"
    environment:
      # El api-service también se beneficia del balanceo de carga interno de Docker
      # al hablar con las réplicas de management-api.
      - MANAGEMENT_API_URL=http://management-api:9000 
    command: uvicorn api:app --host 0.0.0.0 --port 8000

  # SOLUCIÓN #2: La GUI ahora es el cliente inteligente
  gui-service:
    build: .
    container_name: gui-service # La GUI es única, así que puede tener nombre.
    depends_on:
      - management-api
      - api-service
    ports:
      - "8501:8501"
    environment:
      # Pasamos la información necesaria para que el ResilientClient haga su trabajo.
      - MANAGEMENT_API_SERVICE_NAME=management-api
      - MANAGEMENT_API_PORT=9000
      # La URL de inferencia puede apuntar al nombre del servicio; Docker hará un balanceo de carga simple (round-robin).
      - INFERENCE_API_URL=http://api-service:8000 
      - RAY_DASHBOARD_URL=http://ray-head:8265
      - RAY_ADDRESS=ray://ray-head:10001
    command: streamlit run gui.py --server.port=8501 --server.address=0.0.0.0